{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7723846a-3965-452c-9d4f-d84d4637c4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting static/index.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile static/index.html\n",
    "<!doctype html>\n",
    "<html>\n",
    "    <head>\n",
    "        <meta charset=\"utf-8\">\n",
    "        <title>KoGPT2novel</title>\n",
    "        <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/materialize/1.0.0/css/materialize.min.css\">\n",
    "        <style>\n",
    "        .card{\n",
    "            animation: slide-up 0.4s ease;\n",
    "        }\n",
    "        @keyframes slide-up {\n",
    "            0% {\n",
    "                opacity: 0;\n",
    "                transform: translateY(100px);\n",
    "            }\n",
    "            100% {\n",
    "                opacity: 1;\n",
    "                transform: translateY(0);\n",
    "            }\n",
    "        }\n",
    "        #loading{\n",
    "            display:none;\n",
    "        }\n",
    "        #output{\n",
    "            font-size: 20px;\n",
    "            display:none;\n",
    "        }\n",
    "        #output::after{\n",
    "            content: \"|\";\n",
    "            animation: blink .75s step-end infinite;\n",
    "        }\n",
    "        @keyframes blink {\n",
    "            from, to { color: transparent }\n",
    "            50% { color: DeepSkyBlue }\n",
    "        }\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <nav>\n",
    "            <div class=\"nav-wrapper blue\">\n",
    "                <a href=\"#\" class=\"brand-logo center\">KoGPT2novel</a>\n",
    "            </div>\n",
    "        </nav>\n",
    "        <div class=\"container\">\n",
    "            <div class=\"row center\">\n",
    "                <div class=\"col s12 m9 offset-m1 l8 offset-l2\">\n",
    "                    <div class=\"card \">\n",
    "                        <div class=\"card-content\">\n",
    "                            <div class=\"row center \">\n",
    "                              <div class=\"col s10 offset-s1\">\n",
    "                                \n",
    "                                <div class=\"row\">\n",
    "                                    <div class=\"input-field col s12\">\n",
    "                                      <input type=\"text\" id=\"textInput\">\n",
    "                                      <label for=\"textInput\">Write Text</label>\n",
    "                                    </div>\n",
    "                                </div>\n",
    "                                \n",
    "                                \n",
    "                                <div class=\"row\">\n",
    "                                    <a class=\"waves-effect waves-light btn-small blue\" id=\"generate\">Generate</a>                            \n",
    "                                </div>\n",
    "                                \n",
    "\n",
    "                                <div class=\"row\">\n",
    "                                    <div id=\"loading\">\n",
    "                                        <div class=\"preloader-wrapper big active\">\n",
    "                                          <div class=\"spinner-layer spinner-blue-only\">\n",
    "                                            <div class=\"circle-clipper left\">\n",
    "                                              <div class=\"circle\"></div>\n",
    "                                            </div><div class=\"gap-patch\">\n",
    "                                              <div class=\"circle\"></div>\n",
    "                                            </div><div class=\"circle-clipper right\">\n",
    "                                              <div class=\"circle\"></div>\n",
    "                                            </div>\n",
    "                                          </div>\n",
    "                                        </div>\n",
    "                                    </div>                           \n",
    "                                    <p class=\"header col s12 light\" id=\"output\"></p> \n",
    "                                </div>\n",
    "\n",
    "                              </div>\n",
    "                            </div>\n",
    "                        </div>\n",
    "                    </div>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "\n",
    "\n",
    "        <script src=\"https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js\"></script>\n",
    "        <script src=\"https://cdnjs.cloudflare.com/ajax/libs/materialize/1.0.0/js/materialize.min.js\"></script>\n",
    "        <script src=\"https://unpkg.com/axios/dist/axios.min.js\"></script>\n",
    "        <script>\n",
    "\n",
    "        let processing=false;\n",
    "        let intervalId=null;\n",
    "        \n",
    "        //detect enter key\n",
    "        $('#textInput').keypress(e => {\n",
    "          if (e.which == 13) {\n",
    "              processText()\n",
    "          }\n",
    "        });\n",
    "        $(\"#generate\").click(processText);\n",
    "        \n",
    "        async function processText() {\n",
    "            if (processing==true) return \n",
    "            processing=true\n",
    "        \n",
    "            let inputText= $(\"#textInput\").val();\n",
    "            let result=\"\"\n",
    "            $('#output').hide();\n",
    "            $('#loading').show();\n",
    "            if(inputText.length>1){\n",
    "                try {\n",
    "                    const response = await axios.post('/predict',{\"text\": inputText});\n",
    "                    result=response.data[\"result\"];\n",
    "                } catch (error) {\n",
    "                    console.error(error);\n",
    "                    result=error.stack;\n",
    "                    if (error.response.status==504){\n",
    "                        result=\"Server is busy\"\n",
    "                    }\n",
    "                }                \n",
    "            }else{\n",
    "                result=\"Input is too short\"\n",
    "            }\n",
    "\n",
    "           $('#loading').hide();           \n",
    "           $('#output').show(); \n",
    "           doTypingEffect(result);\n",
    "           processing=false;\n",
    "        };\n",
    "        \n",
    "        function doTypingEffect(str){\n",
    "            clearInterval(intervalId);\n",
    "            let i=0;\n",
    "            $(\"#output\").text(\"\");\n",
    "            intervalId=setInterval(function (){\n",
    "                if(str.length<=i) clearInterval(intervalId);\n",
    "                $(\"#output\").append(str[i++])\n",
    "            }, 50);\n",
    "        }\n",
    "        </script>\n",
    "    </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7f3ca628-283f-45f1-894b-fa4bf1370de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting BentomlService.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile BentomlService.py\n",
    "\n",
    "import bentoml\n",
    "import json\n",
    "from bentoml.adapters import JsonInput\n",
    "from bentoml.frameworks.transformers import TransformersModelArtifact\n",
    "from bentoml.types import JsonSerializable, InferenceError, InferenceResult\n",
    "\n",
    "\n",
    "\n",
    "@bentoml.env(pip_packages=[\n",
    "    \"torch==1.7.1\",\n",
    "    \"transformers==4.10.2\"\n",
    "])\n",
    "@bentoml.artifacts([TransformersModelArtifact(\"model\")])\n",
    "@bentoml.web_static_content('./static')\n",
    "class TransformerService(bentoml.BentoService):\n",
    "    @bentoml.api(input=JsonInput(), batch=False)\n",
    "    def predict(self, parsed_json: JsonSerializable):\n",
    "        text = parsed_json.get(\"text\")    \n",
    "        model = self.artifacts.model.get(\"model\")\n",
    "        tokenizer = self.artifacts.model.get(\"tokenizer\")\n",
    "    \n",
    "        #model process\n",
    "        inputs = tokenizer.encode(text, return_tensors=\"pt\", max_length=128, truncation=True)\n",
    "        output = model.generate(inputs, \n",
    "                                max_length=128, \n",
    "                                repetition_penalty=2.0,\n",
    "                                use_cache=True,\n",
    "                               )\n",
    "        output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        \n",
    "        #json\n",
    "        json_out = json.dumps({\n",
    "            \"result\": output\n",
    "        })\n",
    "        return InferenceResult(\n",
    "            data=json_out,\n",
    "            http_status=200,\n",
    "            http_headers={\"Content-Type\": \"application/json\"},\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8d241880-2a32-44cd-83f5-c228af585361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65101692627a4da39e2b9f410380d2ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.11k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a7b39a0afb4945a268e1b13e156043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/513M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast\n",
    "from BentomlService import TransformerService\n",
    "\n",
    "    \n",
    "model_name = \"ttop324/kogpt2novel\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name,\n",
    "  bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
    "  pad_token='<pad>', mask_token='<mask>') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7da2e79d-97ab-4af7-b268-afc29e707b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-09-19 17:12:11,037] INFO - BentoService bundle 'TransformerService:20210919171206_228F50' saved to: /home/user/bentoml/repository/TransformerService/20210919171206_228F50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/user/bentoml/repository/TransformerService/20210919171206_228F50'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service = TransformerService()\n",
    "service.pack(\"model\", {\n",
    "    \"model\": model,\n",
    "    \"tokenizer\": tokenizer\n",
    "})\n",
    "service.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cbb88a32-36a0-413f-9035-b00bd4f19f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-09-19 17:12:15,981] INFO - Getting latest version TransformerService:20210919171206_228F50\n",
      "\u001b[39mFound Bento: /home/user/bentoml/repository/TransformerService/20210919171206_228F50\u001b[0m\n",
      "Containerizing TransformerService:20210919171206_228F50 with local YataiService and docker daemon from local environment|\u001b[32m\n",
      "Build container image: ttop324/transformer-service:latest\u001b[0m\n",
      "The push refers to repository [docker.io/ttop324/transformer-service]\n",
      "\n",
      "\u001b[1B66859589: Preparing \n",
      "\u001b[1B1e372a5e: Preparing \n",
      "\u001b[1B39ea78d6: Preparing \n",
      "\u001b[1B4b8d575f: Preparing \n",
      "\u001b[1B19e4f924: Preparing \n",
      "\u001b[1Baadfe5cc: Preparing \n",
      "\u001b[1B61d7a0be: Preparing \n",
      "\u001b[1B93cf5172: Preparing \n",
      "\u001b[1B500408ed: Preparing \n",
      "\u001b[1B59c9d32c: Preparing \n",
      "\u001b[1B5605a904: Preparing \n",
      "\u001b[1Bc8cc8a1b: Preparing \n",
      "\u001b[1B7e2bf845: Preparing \n",
      "\u001b[1B404288d7: Preparing \n",
      "\u001b[1B8beeb7d5: Preparing \n",
      "\u001b[1B2b510000: Preparing \n",
      "\u001b[1Ba5b53a93: Preparing \n",
      "\u001b[1B08ab7cf3: Preparing \n",
      "\u001b[1B5b992fc1: Preparing \n",
      "\u001b[1B8986f350: Preparing \n",
      "\u001b[1Bab4c463e: Preparing \n",
      "\u001b[21Be372a5e: Pushed   514.9MB/514.8MB2A\u001b[2K\u001b[17A\u001b[2K\u001b[21A\u001b[2K\u001b[14A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[9A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[7A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[22A\u001b[2K\u001b[21A\u001b[2K\u001b[4A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2K\u001b[21A\u001b[2Klatest: digest: sha256:b7902444883929fc825e3c58230aa8fae568cc4f9c98f7a6786c82c7cb0c32f6 size: 4923\n"
     ]
    }
   ],
   "source": [
    "#build docker\n",
    "!bentoml containerize TransformerService:latest -t ttop324/transformer-service:latest\n",
    "#upload docker\n",
    "!docker push ttop324/transformer-service:latest     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6228d62e-2647-492f-b2a3-e9f6a334adf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-09-19 04:09:46,417] WARNING - Option --enable-microbatch/--disable-microbatch has been deprecated in the current release. The micro-batching option has become the default. Consider using --mb-max-batching=1 to simulate the effect of --disable-microbatch\n",
      "[2021-09-19 04:09:46,420] INFO - Starting BentoML proxy in production mode..\n",
      "[2021-09-19 04:09:46,420] INFO - Starting BentoML API server in production mode..\n",
      "[2021-09-19 04:09:46,550] INFO - Running micro batch service on :5000\n",
      "[2021-09-19 04:09:46 +0000] [25] [INFO] Starting gunicorn 20.1.0\n",
      "[2021-09-19 04:09:46 +0000] [25] [INFO] Listening at: http://0.0.0.0:55795 (25)\n",
      "[2021-09-19 04:09:46 +0000] [25] [INFO] Using worker: sync\n",
      "[2021-09-19 04:09:46 +0000] [26] [INFO] Booting worker with pid: 26\n",
      "[2021-09-19 04:09:46 +0000] [1] [INFO] Starting gunicorn 20.1.0\n",
      "[2021-09-19 04:09:46 +0000] [1] [INFO] Listening at: http://0.0.0.0:5000 (1)\n",
      "[2021-09-19 04:09:46 +0000] [1] [INFO] Using worker: aiohttp.worker.GunicornWebWorker\n",
      "[2021-09-19 04:09:46 +0000] [27] [INFO] Booting worker with pid: 27\n",
      "[2021-09-19 04:09:46,666] INFO - Your system nofile limit is 1048576, which means each instance of microbatch service is able to hold this number of connections at same time. You can increase the number of file descriptors for the server process, or launch more microbatch instances to accept more concurrent connection.\n",
      "[2021-09-19 04:09:47,209] INFO - Detected zipimporter <zipimporter object \"/home/bentoml/bundle/TransformerService/zipimports/locket-0.2.1-py3.6.egg\">\n",
      "^C\n",
      "[2021-09-19 04:13:35 +0000] [1] [INFO] Handling signal: int\n",
      "[2021-09-19 04:13:35 +0000] [27] [INFO] Worker exiting (pid: 27)\n",
      "[2021-09-19 04:13:35 +0000] [25] [INFO] Handling signal: term\n",
      "[2021-09-19 04:13:35 +0000] [26] [INFO] Worker exiting (pid: 26)\n",
      "[2021-09-19 04:13:35 +0000] [25] [INFO] Shutting down: Master\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ncurl -i   --header \"Content-Type: application/json\"   --request POST   --data \\'{\"text\": \"위치추적 전자장치(전자발찌) 훼손 \"}\\'   http://localhost:23776/predict       \\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test docker on local\n",
    "!docker run -p 23776:5000 ttop324/transformer-service:latest --workers=1 --enable-microbatch\n",
    "\n",
    "\"\"\"\n",
    "curl -i \\\n",
    "  --header \"Content-Type: application/json\" \\\n",
    "  --request POST \\\n",
    "  --data '{\"text\": \"전자발찌(위치추적 전자장치) 훼손 전후 여성 2명을 살해한 \"}' \\\n",
    "  http://localhost:23776/predict       \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb664d5-5f9d-43af-b6e2-2c4b1c5757e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kubernautic.com yaml\n",
    "#pod.yaml\n",
    "apiVersion: v1\n",
    "kind: Pod\n",
    "metadata:\n",
    "  name: kogpt2novel\n",
    "  labels:\n",
    "    app: kogpt2novel\n",
    "spec:\n",
    "  containers:\n",
    "  - name: kogpt2novel\n",
    "    image: ttop324/transformer-service:latest\n",
    "    ports:\n",
    "    - containerPort: 5000\n",
    "    resources:\n",
    "      limits:\n",
    "        cpu: \"1\"\n",
    "        memory: 1Gi\n",
    "#service.yaml\n",
    "apiVersion: v1        \n",
    "kind: Service\n",
    "metadata:\n",
    "  name: kogpt2novelservice\n",
    "spec:\n",
    "  selector:\n",
    "    app: kogpt2novel\n",
    "  ports:\n",
    "  - protocol: TCP\n",
    "    port: 10000\n",
    "    targetPort: 5000\n",
    "\n",
    "\n",
    "        \n",
    "#cloud.okteto.com yaml============================\n",
    "services:\n",
    "  web:\n",
    "    image: ttop324/transformer-service:latest\n",
    "    ports:\n",
    "      - 8080:5000\n",
    "    replicas: 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a95d1f-4396-4568-8ecd-5fe1870e4520",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
